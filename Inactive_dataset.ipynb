{"cells":[{"cell_type":"code","source":["\n#import libraries\n#from pyspark.sql.functions import avg\nimport matplotlib.pyplot as plt\n#plt.rcParams['font.size'] = 22\nimport warnings    # To suppress warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport seaborn as sb\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["\n\ndf1 = pd.read_csv('/dbfs/FileStore/tables/PRED_31MAR17.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf2 = pd.read_csv('/dbfs/FileStore/tables/PRED_30JUN17.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf3 = pd.read_csv('/dbfs/FileStore/tables/PRED_31OCT17.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf4 = pd.read_csv('/dbfs/FileStore/tables/PRED_31DEC17.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf5 = pd.read_csv('/dbfs/FileStore/tables/PRED_31MAR18.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf6 = pd.read_csv('/dbfs/FileStore/tables/PRED_30JUN18.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf7 = pd.read_csv('/dbfs/FileStore/tables/PRED_31OCT18.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf8 = pd.read_csv('/dbfs/FileStore/tables/PRED_31DEC18.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\ndf9 = pd.read_csv('/dbfs/FileStore/tables/PRED_MARR19.csv', parse_dates = ['HIRE_EXIT_DATE','LAST_PROMOTION_DATE','MANAGER_LAST_PROMOTION','LAST_ONSITE_TRAVEL_DATE'])\n\n\nlist_df = [df1,df2,df3,df4,df5,df6,df7,df8,df9]\nfor i in list_df:\n  i = i.drop_duplicates().reset_index(drop = True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["\nquarter_dict = {3: 1, 6: 2, 10: 3, 12: 4} # quarter dict\nfor i in list_df:\n    i['Year'] = i[i['EMP_STATUS'] == 'I']['HIRE_EXIT_DATE'].max().year\n    i['Quarter'] = pd.Series(i[i['EMP_STATUS'] == 'I']['HIRE_EXIT_DATE'].max().month).apply(quarter_dict.get)[0]\n    i['Month'] = i[i['EMP_STATUS'] == 'I']['HIRE_EXIT_DATE'].dt.month\nfor i in list_df:\n  i['ID']=i['Quarter'].astype(str)+'_'+i['Year'].astype(str)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["training_set = pd.concat([df1,df2,df3,df4,df5,df6,df7])\nvalidation_set = pd.concat([df8,df9])\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["training_set.head(25)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MASK_EMPLOYEEID</th>\n      <th>EMPLOYEE_AGE</th>\n      <th>GENDER</th>\n      <th>NO_OF_LEAVES</th>\n      <th>TOTAL_REPORTEES</th>\n      <th>BAND</th>\n      <th>DEPARTMENT_ID</th>\n      <th>NO_OF_MANAGER_REPORTEES</th>\n      <th>TECHM_EXPERIENCE</th>\n      <th>TOTAL_EXPERIENCE</th>\n      <th>LAST_HIKE_PERCENT</th>\n      <th>MANAGER_RATING</th>\n      <th>NO_OF_PREVIOUS_EMPLOYERS</th>\n      <th>TENURE_LAST_EMPLOPYER</th>\n      <th>HIGHEST_EDUCATION</th>\n      <th>QUARTILE</th>\n      <th>LAST_PROMOTION_DATE</th>\n      <th>TOTAL_PROMOTIONS</th>\n      <th>MANAGER_LAST_PROMOTION</th>\n      <th>LAST_ONSITE_TRAVEL_DATE</th>\n      <th>LAST_ONSITE_TRAVEL_DAYS</th>\n      <th>REWARDS</th>\n      <th>PRIMARY_SKILL</th>\n      <th>SECONDARY_SKILL</th>\n      <th>BASE_LOCATION_CITY</th>\n      <th>CURRENT_LOCATION_CITY</th>\n      <th>HIRE_LOCATION_CITY</th>\n      <th>RESIGNATION_FLG</th>\n      <th>BILLABILITY_STATUS</th>\n      <th>CURRENT_RATING</th>\n      <th>LAST_RATING</th>\n      <th>ALL_PREVIOUS_RAINGS</th>\n      <th>LATEST_HIKE_PERCENT</th>\n      <th>OFFICERCODE_DESC</th>\n      <th>GRIEVANCE_FLG</th>\n      <th>EMP_STATUS</th>\n      <th>HIRE_EXIT_DATE</th>\n      <th>Year</th>\n      <th>Quarter</th>\n      <th>Month</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41D015FE5430E164</td>\n      <td>39.0</td>\n      <td>M</td>\n      <td>11</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>IMS00</td>\n      <td>26</td>\n      <td>12.1</td>\n      <td>13.7</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1.52</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2015-01-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>SQL Server</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>N</td>\n      <td>C</td>\n      <td>C</td>\n      <td>2006-L,2007-E,2008-E,2009-C,2010-E,2011-E,2012...</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2005-02-11</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E006B574A10D5213</td>\n      <td>34.0</td>\n      <td>M</td>\n      <td>18</td>\n      <td>0</td>\n      <td>P1</td>\n      <td>PROD ENGG</td>\n      <td>29</td>\n      <td>4.9</td>\n      <td>12.3</td>\n      <td>48.44</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>4.92</td>\n      <td>BE/BTech/BScTech</td>\n      <td>3</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2013-07-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Business Analysis</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>2013-E,2014-C,2015-C,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2012-05-14</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DE72B59D51C7B2AE</td>\n      <td>36.0</td>\n      <td>F</td>\n      <td>11</td>\n      <td>21</td>\n      <td>P1</td>\n      <td>IASE</td>\n      <td>108</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>35.33</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>DIPLOMA</td>\n      <td>0</td>\n      <td>2016-01-01</td>\n      <td>2</td>\n      <td>2010-07-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Software Quality Assurance</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2006-C,2007-E,2008-E,2009-E,2010-E,2011-C,2012...</td>\n      <td>0.0</td>\n      <td>Initial Training Program</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2005-03-14</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D0776ED5162671E1</td>\n      <td>46.0</td>\n      <td>M</td>\n      <td>5</td>\n      <td>0</td>\n      <td>P2</td>\n      <td>IASE</td>\n      <td>336</td>\n      <td>11.6</td>\n      <td>22.2</td>\n      <td>2.12</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>0.38</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2007-07-01</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>2013-12-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Project Management</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2006-C,2007-C,2008-X,2009-C,2010-X,2011-C,2012...</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2005-08-26</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5654CB68AE69AAD9</td>\n      <td>46.0</td>\n      <td>M</td>\n      <td>31</td>\n      <td>1</td>\n      <td>P2</td>\n      <td>IBU-ANZ3</td>\n      <td>29</td>\n      <td>10.1</td>\n      <td>20.7</td>\n      <td>3.11</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>8.44</td>\n      <td>Company Secretery</td>\n      <td>0</td>\n      <td>2011-07-01</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>2014-02-21</td>\n      <td>313</td>\n      <td>1</td>\n      <td>System Programming</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008-C,2009-C,2010-X,2011-C,2012-X,2013-C,2014...</td>\n      <td>0.0</td>\n      <td>FCTP</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2007-02-13</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2E8CB900573C1337</td>\n      <td>40.0</td>\n      <td>M</td>\n      <td>9</td>\n      <td>1</td>\n      <td>U4</td>\n      <td>IMS04C</td>\n      <td>41</td>\n      <td>9.8</td>\n      <td>14.0</td>\n      <td>3.96</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>3.04</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2011-07-01</td>\n      <td>1</td>\n      <td>2010-07-01</td>\n      <td>2013-09-03</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Application Design and Arch</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008-E,2009-E,2010-C,2011-C,2012-E,2013-E,2014...</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2007-06-01</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DBF68CD6BBE1479D</td>\n      <td>38.0</td>\n      <td>M</td>\n      <td>8</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>IDPM</td>\n      <td>5</td>\n      <td>10.0</td>\n      <td>19.1</td>\n      <td>1.80</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>3.26</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>HANA</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008-L,2009-E,2010-E,2011-E,2012-E,2013-E,2014...</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2007-03-16</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7D3E3593B82F6171</td>\n      <td>45.0</td>\n      <td>M</td>\n      <td>33</td>\n      <td>2</td>\n      <td>P1</td>\n      <td>T_ANZ2</td>\n      <td>65</td>\n      <td>10.9</td>\n      <td>16.4</td>\n      <td>1.89</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>0.38</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>IBM DataStage</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>N</td>\n      <td>C</td>\n      <td>E</td>\n      <td>2007-E,2008-E,2009-E,2010-C,2011-C,2012-C,2013...</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2006-05-24</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7A4F482C1BA44A2C</td>\n      <td>28.0</td>\n      <td>F</td>\n      <td>11</td>\n      <td>3</td>\n      <td>U4</td>\n      <td>IBU-TUS-15</td>\n      <td>40</td>\n      <td>0.7</td>\n      <td>6.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.64</td>\n      <td>BE/BTech/BScTech</td>\n      <td>2</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Core Technology</td>\n      <td>NaN</td>\n      <td>NOIDA</td>\n      <td>NOIDA</td>\n      <td>NOIDA</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2016-07-27</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>BE7116D7454CD4F7</td>\n      <td>22.0</td>\n      <td>M</td>\n      <td>1</td>\n      <td>0</td>\n      <td>U1</td>\n      <td>IBCA</td>\n      <td>126</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>BE/BTech/BScTech</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Initial Training Program</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2016-12-08</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>07A019D84CD9934E</td>\n      <td>24.0</td>\n      <td>F</td>\n      <td>1</td>\n      <td>0</td>\n      <td>U1</td>\n      <td>CPIM</td>\n      <td>449</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>BE/BTech/BScTech</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2015-01-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Initial Training Program</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2016-12-08</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>362CB3A3D7230951</td>\n      <td>31.0</td>\n      <td>M</td>\n      <td>17</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>IDM</td>\n      <td>28</td>\n      <td>1.3</td>\n      <td>6.5</td>\n      <td>0.00</td>\n      <td>C</td>\n      <td>2</td>\n      <td>0.59</td>\n      <td>BE/BTech/BScTech</td>\n      <td>3</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2</td>\n      <td>.NET Framework</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>C</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2015-12-28</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>A7059564DC398AE5</td>\n      <td>23.0</td>\n      <td>M</td>\n      <td>26</td>\n      <td>0</td>\n      <td>U1</td>\n      <td>INIS</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1.2</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>Others</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>C</td>\n      <td>NaN</td>\n      <td>CHENNAI</td>\n      <td>CHENNAI</td>\n      <td>CHENNAI</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>C</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>Initial Training Program</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2016-01-21</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>6F88A700FD918E3A</td>\n      <td>26.0</td>\n      <td>F</td>\n      <td>6</td>\n      <td>0</td>\n      <td>U3</td>\n      <td>BT04-A</td>\n      <td>5</td>\n      <td>0.8</td>\n      <td>3.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>3.14</td>\n      <td>BE/BTech/BScTech</td>\n      <td>2</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2010-10-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Core Technology</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>C</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2016-06-13</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>7421E33B45AAF492</td>\n      <td>35.0</td>\n      <td>M</td>\n      <td>10</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>ITLI</td>\n      <td>7</td>\n      <td>0.8</td>\n      <td>8.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>5.18</td>\n      <td>MCA</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2011-07-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>ADMS SERVICES</td>\n      <td>NaN</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2016-06-13</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>B79925E30E0ADA6F</td>\n      <td>44.0</td>\n      <td>M</td>\n      <td>12</td>\n      <td>0</td>\n      <td>P2</td>\n      <td>CECM</td>\n      <td>282</td>\n      <td>5.4</td>\n      <td>17.8</td>\n      <td>1.26</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>4.44</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2016-01-01</td>\n      <td>2014-09-02</td>\n      <td>0</td>\n      <td>5</td>\n      <td>Custom App. Archs.</td>\n      <td>NaN</td>\n      <td>GURGAON</td>\n      <td>GURGAON</td>\n      <td>GURGAON</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>C</td>\n      <td>E</td>\n      <td>2012-C,2013-C,2014-C,2015-E</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2011-10-24</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>E8A5DBD968C551E7</td>\n      <td>38.0</td>\n      <td>M</td>\n      <td>34</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>CECM</td>\n      <td>15</td>\n      <td>7.3</td>\n      <td>11.7</td>\n      <td>2.54</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>4.45</td>\n      <td>DIPLOMA</td>\n      <td>0</td>\n      <td>2011-07-01</td>\n      <td>1</td>\n      <td>2010-07-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Enterprise Content Management</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2010-E,2011-C,2012-E,2013-C,2014-C,2015-E,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2009-12-28</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2637E40652B339E7</td>\n      <td>34.0</td>\n      <td>M</td>\n      <td>2</td>\n      <td>4</td>\n      <td>U4</td>\n      <td>GERMANCHEM</td>\n      <td>338</td>\n      <td>7.1</td>\n      <td>12.1</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.73</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2005-04-01</td>\n      <td>2015-02-09</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Lotus Notes - Technical</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2011-X,2012-X,2013-C,2014-X,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2010-02-22</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>79DF13E1BF4699B4</td>\n      <td>34.0</td>\n      <td>M</td>\n      <td>11</td>\n      <td>0</td>\n      <td>U3</td>\n      <td>CIO-PS</td>\n      <td>5</td>\n      <td>3.6</td>\n      <td>7.9</td>\n      <td>4.96</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>4.25</td>\n      <td></td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PeopleSoft-Financials</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-E,2015-C,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2013-08-07</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>EB35E7E0A5279772</td>\n      <td>27.0</td>\n      <td>M</td>\n      <td>18</td>\n      <td>0</td>\n      <td>U3</td>\n      <td>ROW-SAP</td>\n      <td>8</td>\n      <td>3.4</td>\n      <td>5.7</td>\n      <td>7.31</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2.26</td>\n      <td>BE/BTech/BScTech</td>\n      <td>2</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>DevProcDataIntegr-Netweavr</td>\n      <td>NaN</td>\n      <td>NOIDA</td>\n      <td>GURGAON</td>\n      <td>NOIDA</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>C</td>\n      <td>C</td>\n      <td>2014-E,2015-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2013-11-06</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>B8FBD0AF053047CF</td>\n      <td>30.0</td>\n      <td>M</td>\n      <td>28</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>BT05</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>9.3</td>\n      <td>3.49</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.60</td>\n      <td>BE/BTech/BScTech</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2013-07-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Agile Processes</td>\n      <td>NaN</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-E,2015-C,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2014-03-26</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>DA6801E9F66449F7</td>\n      <td>24.0</td>\n      <td>F</td>\n      <td>23</td>\n      <td>0</td>\n      <td>U2</td>\n      <td>INOR</td>\n      <td>1</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>12.76</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>Others</td>\n      <td>1</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>EAI</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>BENGALURU</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>2014-E,2015-C,2016-C</td>\n      <td>0.0</td>\n      <td>Initial Training Program</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2013-10-01</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>474BA546BA9F46B3</td>\n      <td>25.0</td>\n      <td>F</td>\n      <td>5</td>\n      <td>0</td>\n      <td>U1</td>\n      <td>IGSK</td>\n      <td>3</td>\n      <td>4.4</td>\n      <td>4.4</td>\n      <td>77.75</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2016-01-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Cognos</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>2013-E,2014-C,2015-E,2016-C</td>\n      <td>0.0</td>\n      <td>JTA-NON-MS</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2012-11-23</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>15AA6C74547065C8</td>\n      <td>33.0</td>\n      <td>F</td>\n      <td>16</td>\n      <td>2</td>\n      <td>U4</td>\n      <td>CECM</td>\n      <td>5</td>\n      <td>2.9</td>\n      <td>9.6</td>\n      <td>3.47</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2.10</td>\n      <td>BCS</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2010-07-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>1</td>\n      <td>User Experience</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-E,2015-C,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2014-05-09</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1992F57C591C13EC</td>\n      <td>31.0</td>\n      <td>M</td>\n      <td>3</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>ROUK-IRL-2</td>\n      <td>3</td>\n      <td>2.7</td>\n      <td>8.7</td>\n      <td>6.53</td>\n      <td>L</td>\n      <td>2</td>\n      <td>2.19</td>\n      <td>BE/BTech/BScTech</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Telecom Billing</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-C,2016-C</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2014-07-14</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1_2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["'''\nfor i in list_df:\n  i.replace(' ', np.nan, inplace=True)\n  '''"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["temp1=df1[df1.EMP_STATUS=='A']\ntemp2=df2[df2.EMP_STATUS=='A']\ntemp3=df3[df3.EMP_STATUS=='A']\ntemp4=df4[df4.EMP_STATUS=='A']\ntemp5=df5[df5.EMP_STATUS=='A']\ntemp6=df6[df6.EMP_STATUS=='A']\ntemp7=df7[df7.EMP_STATUS=='A']\ntemp8=df8[df8.EMP_STATUS=='A']\ntemp9=df9[df9.EMP_STATUS=='A']\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["'''training_set = pd.concat([temp1,temp2,temp3,temp4,temp5,temp6,temp7]).drop_duplicates().reset_index(drop=True)\nvalidation_set = pd.concat([temp8,temp9]).drop_duplicates().reset_index(drop=True)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":[""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MASK_EMPLOYEEID</th>\n      <th>EMPLOYEE_AGE</th>\n      <th>GENDER</th>\n      <th>NO_OF_LEAVES</th>\n      <th>TOTAL_REPORTEES</th>\n      <th>BAND</th>\n      <th>DEPARTMENT_ID</th>\n      <th>NO_OF_MANAGER_REPORTEES</th>\n      <th>TECHM_EXPERIENCE</th>\n      <th>TOTAL_EXPERIENCE</th>\n      <th>LAST_HIKE_PERCENT</th>\n      <th>MANAGER_RATING</th>\n      <th>NO_OF_PREVIOUS_EMPLOYERS</th>\n      <th>TENURE_LAST_EMPLOPYER</th>\n      <th>HIGHEST_EDUCATION</th>\n      <th>QUARTILE</th>\n      <th>LAST_PROMOTION_DATE</th>\n      <th>TOTAL_PROMOTIONS</th>\n      <th>MANAGER_LAST_PROMOTION</th>\n      <th>LAST_ONSITE_TRAVEL_DATE</th>\n      <th>LAST_ONSITE_TRAVEL_DAYS</th>\n      <th>REWARDS</th>\n      <th>PRIMARY_SKILL</th>\n      <th>SECONDARY_SKILL</th>\n      <th>BASE_LOCATION_CITY</th>\n      <th>CURRENT_LOCATION_CITY</th>\n      <th>HIRE_LOCATION_CITY</th>\n      <th>RESIGNATION_FLG</th>\n      <th>BILLABILITY_STATUS</th>\n      <th>CURRENT_RATING</th>\n      <th>LAST_RATING</th>\n      <th>ALL_PREVIOUS_RAINGS</th>\n      <th>LATEST_HIKE_PERCENT</th>\n      <th>OFFICERCODE_DESC</th>\n      <th>GRIEVANCE_FLG</th>\n      <th>EMP_STATUS</th>\n      <th>HIRE_EXIT_DATE</th>\n      <th>Year</th>\n      <th>Quarter</th>\n      <th>Month</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>358914</th>\n      <td>0F83D48B6915E624</td>\n      <td>22.0</td>\n      <td>M</td>\n      <td>0</td>\n      <td>0</td>\n      <td>U1</td>\n      <td>ESRM ELITE</td>\n      <td>25</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>BE/BTech/BScTech/BIT/BArch</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2015-01-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CHENNAI</td>\n      <td>CHENNAI</td>\n      <td>CHENNAI</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Initial Training Program</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2018-09-18</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3_2018</td>\n    </tr>\n    <tr>\n      <th>358915</th>\n      <td>CC83EA9F35B025CC</td>\n      <td>24.0</td>\n      <td>M</td>\n      <td>0</td>\n      <td>0</td>\n      <td>U1</td>\n      <td>D-BT ELTP</td>\n      <td>286</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>BE/BTech/BScTech/BIT/BArch</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Initial Training Program</td>\n      <td>NaN</td>\n      <td>A</td>\n      <td>2018-10-11</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3_2018</td>\n    </tr>\n    <tr>\n      <th>358916</th>\n      <td>56C5C51835BEB248</td>\n      <td>28.0</td>\n      <td>M</td>\n      <td>0</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>CIESIOT</td>\n      <td>11</td>\n      <td>0.1</td>\n      <td>5.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1.14</td>\n      <td>BE/BTech/BScTech/BIT/BArch</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Java Enterprise - Server</td>\n      <td>NaN</td>\n      <td>NOIDA</td>\n      <td>NOIDA</td>\n      <td>NOIDA</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2018-09-28</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3_2018</td>\n    </tr>\n    <tr>\n      <th>358917</th>\n      <td>EB84129FE6AED3EA</td>\n      <td>34.0</td>\n      <td>M</td>\n      <td>1</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>NS-GDCEFUS</td>\n      <td>129</td>\n      <td>0.2</td>\n      <td>8.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>2.43</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Cisco Routing</td>\n      <td>NaN</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2018-09-03</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3_2018</td>\n    </tr>\n    <tr>\n      <th>358918</th>\n      <td>65C3D5062A315B02</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>0</td>\n      <td>0</td>\n      <td>U4</td>\n      <td>NS-RELEASE</td>\n      <td>78</td>\n      <td>0.2</td>\n      <td>6.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>3.15</td>\n      <td>MCA</td>\n      <td>0</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>2016-01-01</td>\n      <td>NaT</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Project Management</td>\n      <td>NaN</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>HYDERABAD</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>2018-08-03</td>\n      <td>2018</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3_2018</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["fd1=pd.merge(temp1[['MASK_EMPLOYEEID','EMP_STATUS']],df2,how='inner',on=['MASK_EMPLOYEEID'])\nfd2=pd.merge(temp2[['MASK_EMPLOYEEID','EMP_STATUS']],df3,how='inner',on=['MASK_EMPLOYEEID'])\nfd3=pd.merge(temp3[['MASK_EMPLOYEEID','EMP_STATUS']],df4,how='inner',on=['MASK_EMPLOYEEID'])\nfd4=pd.merge(temp4[['MASK_EMPLOYEEID','EMP_STATUS']],df5,how='inner',on=['MASK_EMPLOYEEID'])\nfd5=pd.merge(temp5[['MASK_EMPLOYEEID','EMP_STATUS']],df6,how='inner',on=['MASK_EMPLOYEEID'])\nfd6=pd.merge(temp6[['MASK_EMPLOYEEID','EMP_STATUS']],df7,how='inner',on=['MASK_EMPLOYEEID'])\nfd7=pd.merge(temp7[['MASK_EMPLOYEEID','EMP_STATUS']],df8,how='inner',on=['MASK_EMPLOYEEID'])\nfd8=pd.merge(temp8[['MASK_EMPLOYEEID','EMP_STATUS']],df9,how='inner',on=['MASK_EMPLOYEEID'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["\n\n\n#Deletng EMP_STATUS column from original df\nfor i in range(8):\n    data=globals()[\"fd\" + str(i + 1)]\n    data.drop(['EMP_STATUS_x'],axis=1,inplace=True)\n    data.rename(columns={'EMP_STATUS_y':'TARGET_VALUE'},inplace=True)\n    globals()[\"fd\" + str(i + 1)]=data"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["f1 = df2.append(df3)\nf1 = df2.append(df4)\ntriple1=pd.merge(temp1[['MASK_EMPLOYEEID','EMP_STATUS']],f1,how='inner',on=['MASK_EMPLOYEEID'])\n\nf2 = df3.append(df4)\nf2 = df3.append(df5)\ntriple2=pd.merge(temp2[['MASK_EMPLOYEEID','EMP_STATUS']],f2,how='inner',on=['MASK_EMPLOYEEID'])\n\nf3 = df4.append(df5)\nf3 = df4.append(df6)\ntriple3=pd.merge(temp3[['MASK_EMPLOYEEID','EMP_STATUS']],f3,how='inner',on=['MASK_EMPLOYEEID'])\n\nf4 = df5.append(df6)\nf4 = df5.append(df7)\ntriple4=pd.merge(temp4[['MASK_EMPLOYEEID','EMP_STATUS']],f4,how='inner',on=['MASK_EMPLOYEEID'])\n\n\nf5 = df6.append(df7)\nf5 = df6.append(df8)\ntriple5=pd.merge(temp5[['MASK_EMPLOYEEID','EMP_STATUS']],f5,how='inner',on=['MASK_EMPLOYEEID'])\n\n\nlist_f = [triple1,triple2,triple3,triple4,triple5]\nfor i in list_f:\n  i['MASK_EMPLOYEEID'] = i['MASK_EMPLOYEEID'].drop_duplicates( keep='last', inplace=False)\n\n\n#triples['MASK_EMPLOYEEID'].drop_duplicates().reset_index(drop = True)\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["\n#Deletng EMP_STATUS column from original df\nfor i in range(5):\n    data=globals()[\"triple\" + str(i + 1)]\n    data.drop(['EMP_STATUS_x'],axis=1,inplace=True)\n    data.rename(columns={'EMP_STATUS_y':'TARGET_VALUE'},inplace=True)\n    globals()[\"triple\" + str(i + 1)]=data"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["'''y1 = df2.append(df3)\ny1 = df2.append(df4)\nyear1=pd.merge(temp1[['MASK_EMPLOYEEID','EMP_STATUS']],y1,how='inner',on=['MASK_EMPLOYEEID'])\nyear1['MASK_EMPLOYEEID'] = year1['MASK_EMPLOYEEID'].drop_duplicates( keep='last', inplace=False)\n#year1 = year1.drop_duplicates(keep=False,inplace=True)\n\ny2 = df6.append(df7)\ny2 = df6.append(df8)\nyear2=pd.merge(temp5[['MASK_EMPLOYEEID','EMP_STATUS']],y2,how='inner',on=['MASK_EMPLOYEEID'])\nyear2['MASK_EMPLOYEEID'] = year2['MASK_EMPLOYEEID'].drop_duplicates( keep='last', inplace=False)\n#year2 = year2.drop_duplicates(keep=False,inplace=True)\n\n'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: &#34;y1 = df2.append(df3)\\ny1 = df2.append(df4)\\nyear1=pd.merge(temp1[[&#39;MASK_EMPLOYEEID&#39;,&#39;EMP_STATUS&#39;]],y1,how=&#39;inner&#39;,on=[&#39;MASK_EMPLOYEEID&#39;])\\nyear1[&#39;MASK_EMPLOYEEID&#39;] = year1[&#39;MASK_EMPLOYEEID&#39;].drop_duplicates( keep=&#39;last&#39;, inplace=False)\\n#year1 = year1.drop_duplicates(keep=False,inplace=True)\\n\\ny2 = df6.append(df7)\\ny2 = df6.append(df8)\\nyear2=pd.merge(temp5[[&#39;MASK_EMPLOYEEID&#39;,&#39;EMP_STATUS&#39;]],y2,how=&#39;inner&#39;,on=[&#39;MASK_EMPLOYEEID&#39;])\\nyear2[&#39;MASK_EMPLOYEEID&#39;] = year2[&#39;MASK_EMPLOYEEID&#39;].drop_duplicates( keep=&#39;last&#39;, inplace=False)\\n#year2 = year2.drop_duplicates(keep=False,inplace=True)\\n\\n&#34;</div>"]}}],"execution_count":15},{"cell_type":"code","source":["'''\n#Deletng EMP_STATUS column from original df\nfor i in range(2):\n    data=globals()[\"year\" + str(i + 1)]\n    data.drop(['EMP_STATUS_x'],axis=1,inplace=True)\n    data.rename(columns={'EMP_STATUS_y':'TARGET_VALUE'},inplace=True)\n    globals()[\"year\" + str(i + 1)]=data'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: &#39;\\n#Deletng EMP_STATUS column from original df\\nfor i in range(2):\\n    data=globals()[&#34;year&#34; + str(i + 1)]\\n    data.drop([\\&#39;EMP_STATUS_x\\&#39;],axis=1,inplace=True)\\n    data.rename(columns={\\&#39;EMP_STATUS_y\\&#39;:\\&#39;TARGET_VALUE\\&#39;},inplace=True)\\n    globals()[&#34;year&#34; + str(i + 1)]=data&#39;</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["#mapping completed"],"metadata":{}},{"cell_type":"code","source":["llist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\n# print(fd1.QUARTILE.value_counts())\nfor i in llist:\n  print('------------------')\n  print(i.QUARTILE.value_counts())\n  print((i[i.TARGET_VALUE=='I'].QUARTILE.value_counts()*100)/i.QUARTILE.value_counts())"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["labels=fd1.QUARTILE.value_counts().index\n# colors=[\"olive\",\"orange\",\"hotpink\",\"slateblue\",\"y\",\"lime\"]\n#explode=[0,0,0,0,0,0]\nsizes=(fd1[fd1.TARGET_VALUE=='I'].QUARTILE.value_counts()*100)/fd1.QUARTILE.value_counts().values\nplt.figure(figsize=(7,7))\nplt.pie(sizes,labels=labels,autopct=\"%1.1f%%\")\nplt.title(\"Quartile Counts\",color=\"saddlebrown\",fontsize=15)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["labels=fd1.QUARTILE.value_counts().index\n# colors=[\"olive\",\"orange\",\"hotpink\",\"slateblue\",\"y\",\"lime\"]\n#explode=[0,0,0,0,0,0]\nsizes=i[i.TOTAL_EXPERIENCE<=3].QUARTILE.value_counts().values\nplt.figure(figsize=(7,7))\nplt.pie(sizes,labels=labels,autopct=\"%1.1f%%\")\nplt.title(\"Education Field Counts\",color=\"saddlebrown\",fontsize=15)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["var1=pd.crosstab(data[\"QUARTILE\"],data['TARGET_VALUE'])\nvar1.div(var1.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize = (10,5)) \n  #plt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#total percentage of experienced and inexperienced employee in each quartile for each quarter\nllist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nl=[0.0,1.0,2.0,3.0,4.0]\nj=1\nfor i in llist:\n  print('Quarter ' , str(j))\n  print('total percent of inexperienced employee')\n  print(i[i.TOTAL_EXPERIENCE<=3].QUARTILE.value_counts()*100/i.QUARTILE.value_counts())\n  print('total percent of experienced employee')\n  print(i[i.TOTAL_EXPERIENCE>3].QUARTILE.value_counts()*100/i.QUARTILE.value_counts())\n  j+=1"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#percentage of experienced and inexperienced people who are attriting\n\n\nllist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nl=[0.0,1.0,2.0,3.0,4.0]\nj=1\nfor i in llist:\n  print('Quarter ' , str(j))\n  print('total percent of inexperienced employee')\n  print(i[i.TOTAL_EXPERIENCE<=3][i.TARGET_VALUE=='I'].QUARTILE.value_counts()*100/i[i.TOTAL_EXPERIENCE<=3].QUARTILE.value_counts())\n  print('total percent of experienced employee')\n  print(i[i.TOTAL_EXPERIENCE>3][i.TARGET_VALUE=='I'].QUARTILE.value_counts()*100/i[i.TOTAL_EXPERIENCE>3].QUARTILE.value_counts())\n  print('-----------')\n  j+=1"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["\n#tech mahindra experience per quartile\n\nllist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nl=[0.0,1.0,2.0,3.0,4.0]\nj=1\nfor i in llist:\n  print(i[i.TECHM_EXPERIENCE<=2].QUARTILE.value_counts()*100/i.QUARTILE.value_counts())"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["\n# (fd1[fd1.TARGET_VALUE=='I'].TOTAL_EXPERIENCE.value_counts()>3).sum(),fd1[fd1.TARGET_VALUE=='I'].TOTAL_EXPERIENCE.value_counts()\n# fd1[fd1.TARGET_VALUE=='I'][fd1.TOTAL_EXPERIENCE>2].TOTAL_PROMOTIONS.value_counts(),fd1[fd1.TARGET_VALUE=='I'].TOTAL_EXPERIENCE.mean()\n\nj=1\nfor i in llist:\n    print('QUARTER NUMBER ',str(j))\n    print('the percentage of total inexperienced and experienced',i[i.TOTAL_EXPERIENCE<=2].TOTAL_EXPERIENCE.value_counts().sum()*100/i.TOTAL_EXPERIENCE.value_counts().sum(),i[i.TOTAL_EXPERIENCE>2].TOTAL_EXPERIENCE.value_counts().sum()*100/i.TOTAL_EXPERIENCE.value_counts().sum())\n    print('percent of the inexperienced who are leaving',i[i.TOTAL_EXPERIENCE<=3][i.TARGET_VALUE=='I'].TOTAL_EXPERIENCE.value_counts().sum()*100/i[i.TOTAL_EXPERIENCE<=3].TOTAL_EXPERIENCE.value_counts().sum())\n    print('percent of the experienced who are leaving',i[i.TOTAL_EXPERIENCE<=3][i.TARGET_VALUE=='I'].TOTAL_EXPERIENCE.value_counts().sum()*100/i[i.TOTAL_EXPERIENCE>3].TOTAL_EXPERIENCE.value_counts().sum())\n    print('-------------------')\n    j+=1"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["\nj=1\nfor i in llist:\n  print('for QUARTER ',str(j))\n  print((i[i.TARGET_VALUE=='I'][i.TOTAL_EXPERIENCE<=3].TOTAL_PROMOTIONS.value_counts()*100)/i[i.TARGET_VALUE=='I'][i.TOTAL_EXPERIENCE<=3].TOTAL_PROMOTIONS.value_counts().sum())\n  print((i[i.TARGET_VALUE=='I'][i.TOTAL_EXPERIENCE>3].TOTAL_PROMOTIONS.value_counts()*100)/i[i.TARGET_VALUE=='I'][i.TOTAL_EXPERIENCE>3].TOTAL_PROMOTIONS.value_counts().sum())\n  print('-------------------------')\n  j+=1"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["def stripplott(variable):\n  f,ax=plt.subplots(figsize=(18,18))\n  sb.set(rc={'figure.figsize':(16,20)})\n  sb.stripplot(x='TARGET_VALUE', y=variable, data=fd1, alpha=0.3, jitter=True);\n  # plt.plot()\n  display()\n  stripplott(\"TOTAL_EXPERIENCE\")"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["f,ax=plt.subplots(figsize=(18,18))\nsb.set(rc={'figure.figsize':(100,50)})\n# sb.countplot(x='BAND',data=fd3)\nsb.factorplot(x='TARGET_VALUE',col='TOTAL_PROMOTIONS',kind='count',data=fd1)\n# fd1.groupby('NO_OF_LEAVES').BAND.hist(alpha=0.6)\n# fig, ax = plt.subplots(1, 2, figsize=(300, 100))\n# sb.kdeplot(fd1.loc[fd1['TARGET_VALUE'] == 'I', 'NO_OF_MANAGER_REPORTEES'], ax=ax[0], label='INACTIVE(0)')\n# sb.kdeplot(fd1.loc[fd1['TARGET_VALUE'] == 'A', 'NO_OF_MANAGER_REPORTEES'], ax=ax[0], label='ACTIVE(1)')\n# plt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["# PRE - PROCESSING"],"metadata":{}},{"cell_type":"code","source":["#retain original copy\ndata1 = validation_set.copy()\n#data1 = training_set.copy()\n\n#validation_set = pd.concat([fd1,fd2,fd3,fd4,fd5,fd6]).drop_duplicates().reset_index(drop=True)\n#data = fd8[fd8.TARGET_VALUE=='I'].copy()\n#data1 = fd8.copy()\n#llist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["data1.rename(columns={'EMP_STATUS':'TARGET_VALUE'},inplace=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["\ncat_df = data1.select_dtypes(include=['object']).copy()\ncat_df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MASK_EMPLOYEEID</th>\n      <th>GENDER</th>\n      <th>BAND</th>\n      <th>DEPARTMENT_ID</th>\n      <th>MANAGER_RATING</th>\n      <th>HIGHEST_EDUCATION</th>\n      <th>PRIMARY_SKILL</th>\n      <th>SECONDARY_SKILL</th>\n      <th>BASE_LOCATION_CITY</th>\n      <th>CURRENT_LOCATION_CITY</th>\n      <th>HIRE_LOCATION_CITY</th>\n      <th>RESIGNATION_FLG</th>\n      <th>BILLABILITY_STATUS</th>\n      <th>CURRENT_RATING</th>\n      <th>LAST_RATING</th>\n      <th>ALL_PREVIOUS_RAINGS</th>\n      <th>OFFICERCODE_DESC</th>\n      <th>GRIEVANCE_FLG</th>\n      <th>TARGET_VALUE</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>528AFF033442DDC8</td>\n      <td>M</td>\n      <td>U3</td>\n      <td>ICS07B</td>\n      <td>NaN</td>\n      <td>BE/BTech/BScTech/BIT/BArch</td>\n      <td>Infra Operations Skill</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>2014-E,2015-C,2016-C,2017-C</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>4_2018</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A52F356BB9D63428</td>\n      <td>M</td>\n      <td>U4</td>\n      <td>IES-IDM&amp;M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>.NET Framework</td>\n      <td>NaN</td>\n      <td>CHENNAI</td>\n      <td>CHENNAI</td>\n      <td>CHENNAI</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>2012-C,2013-E,2014-E,2015-C,2016-C,2017-C</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>4_2018</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BA5E48FB287070A3</td>\n      <td>M</td>\n      <td>U3</td>\n      <td>IES A&amp;D</td>\n      <td>NaN</td>\n      <td>BE/BTech/BScTech/BIT/BArch</td>\n      <td>Aerospace &amp; Defense</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>X</td>\n      <td>2013-X,2014-X,2015-X,2016-X,2017-X</td>\n      <td>Initial Training Program</td>\n      <td>Y</td>\n      <td>A</td>\n      <td>4_2018</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A909AA71C7C5329D</td>\n      <td>M</td>\n      <td>U4</td>\n      <td>IBU-CSP-04</td>\n      <td>NaN</td>\n      <td>MSc</td>\n      <td>Web Application Development</td>\n      <td>NaN</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>PUNE</td>\n      <td>N</td>\n      <td>N</td>\n      <td>NaN</td>\n      <td>X</td>\n      <td>2014-C,2015-C,2016-C,2017-X</td>\n      <td>Lateral Joinees</td>\n      <td>N</td>\n      <td>A</td>\n      <td>4_2018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BB7133C78C3D7683</td>\n      <td>M</td>\n      <td>U2</td>\n      <td>IGEE</td>\n      <td>NaN</td>\n      <td>BE/BTech/BScTech/BIT/BArch</td>\n      <td>Test Management</td>\n      <td>NaN</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>BENGALURU</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>2017-C</td>\n      <td>Initial Training Program</td>\n      <td>N</td>\n      <td>A</td>\n      <td>4_2018</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["\ndata1['PROMOTION_FLAG']=data1.apply(lambda data1 : 1 if data1.LAST_PROMOTION_DATE.year>2016 and data1.LAST_PROMOTION_DATE.month<6 else 0,axis=1)\n'''for i in llist:\n    #fd1['PROMOTION_FLAG']=fd1.apply(lambda fd1 : 1 if fd1.LAST_PROMOTION_DATE.year>2016 and fd1.LAST_PROMOTION_DATE.month<6 else 0,axis=1)\n    i['PROMOTION_FLAG']=i.apply(lambda i : 1 if i.LAST_PROMOTION_DATE.year>2016 and i.LAST_PROMOTION_DATE.month<6 else 0,axis=1)'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: &#34;for i in llist:\\n    #fd1[&#39;PROMOTION_FLAG&#39;]=fd1.apply(lambda fd1 : 1 if fd1.LAST_PROMOTION_DATE.year&gt;2016 and fd1.LAST_PROMOTION_DATE.month&lt;6 else 0,axis=1)\\n    i[&#39;PROMOTION_FLAG&#39;]=i.apply(lambda i : 1 if i.LAST_PROMOTION_DATE.year&gt;2016 and i.LAST_PROMOTION_DATE.month&lt;6 else 0,axis=1)&#34;</div>"]}}],"execution_count":33},{"cell_type":"code","source":["#data2=fd1.copy()\n#data2.info()\ndata1['CITY_FLAG']=data1.apply(lambda data1 : 1 if data1.HIRE_LOCATION_CITY==data1.CURRENT_LOCATION_CITY else 0,axis=1 )\n\n'''for i in llist:\n    i['CITY_FLAG']=i.apply(lambda i : 1 if i.HIRE_LOCATION_CITY==i.CURRENT_LOCATION_CITY else 0,axis=1 )'''\n#data1.CITY_FLAG.value_counts()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: &#34;for i in llist:\\n    i[&#39;CITY_FLAG&#39;]=i.apply(lambda i : 1 if i.HIRE_LOCATION_CITY==i.CURRENT_LOCATION_CITY else 0,axis=1 )&#34;</div>"]}}],"execution_count":34},{"cell_type":"code","source":["'''data1.PRIMARY_SKILL.fillna(data1.SECONDARY_SKILL.str[0],inplace=True)\ndata[\"PRIMARY_SKILL\"]= data[\"PRIMARY_SKILL\"].str.replace(np.nan, \"New Boston\", case = False)\ndata[\"PRIMARY_SKILL\"]'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: &#39;data1.PRIMARY_SKILL.fillna(data1.SECONDARY_SKILL.str[0],inplace=True)\\ndata[&#34;PRIMARY_SKILL&#34;]= data[&#34;PRIMARY_SKILL&#34;].str.replace(np.nan, &#34;New Boston&#34;, case = False)\\ndata[&#34;PRIMARY_SKILL&#34;]&#39;</div>"]}}],"execution_count":35},{"cell_type":"code","source":["data1.CURRENT_RATING.fillna(data1.LAST_RATING,inplace=True)\n'''for i in llist:\n    i.CURRENT_RATING.fillna(i.LAST_RATING,inplace=True)'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: &#39;for i in llist:\\n    i.CURRENT_RATING.fillna(i.LAST_RATING,inplace=True)&#39;</div>"]}}],"execution_count":36},{"cell_type":"code","source":["data1.CURRENT_RATING.fillna(data1.ALL_PREVIOUS_RAINGS.str[-1],inplace=True)\n'''for i in llist:\n    i.CURRENT_RATING.fillna(i.ALL_PREVIOUS_RAINGS.str[-1],inplace=True)'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: &#39;for i in llist:\\n    i.CURRENT_RATING.fillna(i.ALL_PREVIOUS_RAINGS.str[-1],inplace=True)&#39;</div>"]}}],"execution_count":37},{"cell_type":"code","source":["data1.columns"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["import pickle\n\npickle_in = open(\"band.pickle\",\"rb\")\ndict_band = pickle.load(pickle_in)\n#print(dict_band)\n\npickle_in = open(\"education.pickle\",\"rb\")\ndict_education = pickle.load(pickle_in)\n#print(dict_education)\n\npickle_in = open(\"rating.pickle\",\"rb\")\ndict_rating = pickle.load(pickle_in)\n#print(dict_rating)\n\npickle_in = open(\"education_name.pickle\",\"rb\")\ndict_edu_name = pickle.load(pickle_in)\n#print(dict_edu_name)\n\npickle_in = open(\"gender.pickle\",\"rb\")\ndict_gender = pickle.load(pickle_in)\n#print(dict_gender)\n\npickle_in = open(\"generic.pickle\",\"rb\")\ndict_generic = pickle.load(pickle_in)\n#print(dict_generic)\n\npickle_in = open(\"target.pickle\",\"rb\")\ndict_target = pickle.load(pickle_in)\n#print(dict_target)\n\n#print(example_dict[3])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["data1['HIGHEST_EDUCATION'].replace(dict_edu_name, inplace=True)\n'''for i in llist:\n    i['HIGHEST_EDUCATION'].replace(dict_edu_name, inplace=True)'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: &#34;for i in llist:\\n    i[&#39;HIGHEST_EDUCATION&#39;].replace(dict_edu_name, inplace=True)&#34;</div>"]}}],"execution_count":40},{"cell_type":"code","source":["data1['BAND'].replace(dict_band, inplace=True)\ndata1['CURRENT_RATING'].replace(dict_rating, inplace=True)\ndata1['LAST_RATING'].replace(dict_rating, inplace=True)\ndata1['MANAGER_RATING'].replace(dict_rating, inplace=True)\ndata1['HIGHEST_EDUCATION'].replace(dict_education, inplace=True)\ndata1['GENDER'].replace(dict_gender, inplace=True)\ndata1['GRIEVANCE_FLG'].replace(dict_generic, inplace=True)\ndata1['BILLABILITY_STATUS'].replace(dict_generic, inplace=True)\ndata1['RESIGNATION_FLG'].replace(dict_generic, inplace=True)\ndata1['TARGET_VALUE'].replace(dict_target, inplace=True)\n\n'''\nfor i in llist:\n    i['BAND'].replace(dict_band, inplace=True)\n    i['CURRENT_RATING'].replace(dict_rating, inplace=True)\n    i['LAST_RATING'].replace(dict_rating, inplace=True)\n    i['MANAGER_RATING'].replace(dict_rating, inplace=True)\n    i['HIGHEST_EDUCATION'].replace(dict_education, inplace=True)'''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[23]: &#34;\\nfor i in llist:\\n    i[&#39;BAND&#39;].replace(dict_band, inplace=True)\\n    i[&#39;CURRENT_RATING&#39;].replace(dict_rating, inplace=True)\\n    i[&#39;LAST_RATING&#39;].replace(dict_rating, inplace=True)\\n    i[&#39;MANAGER_RATING&#39;].replace(dict_rating, inplace=True)\\n    i[&#39;HIGHEST_EDUCATION&#39;].replace(dict_education, inplace=True)&#34;</div>"]}}],"execution_count":41},{"cell_type":"code","source":["\nprint(data1.dtypes)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MASK_EMPLOYEEID                     object\nEMPLOYEE_AGE                       float64\nGENDER                               int64\nNO_OF_LEAVES                         int64\nTOTAL_REPORTEES                      int64\nBAND                                 int64\nDEPARTMENT_ID                       object\nNO_OF_MANAGER_REPORTEES              int64\nTECHM_EXPERIENCE                   float64\nTOTAL_EXPERIENCE                   float64\nLAST_HIKE_PERCENT                  float64\nMANAGER_RATING                     float64\nNO_OF_PREVIOUS_EMPLOYERS             int64\nTENURE_LAST_EMPLOPYER              float64\nHIGHEST_EDUCATION                  float64\nQUARTILE                             int64\nLAST_PROMOTION_DATE         datetime64[ns]\nTOTAL_PROMOTIONS                     int64\nMANAGER_LAST_PROMOTION      datetime64[ns]\nLAST_ONSITE_TRAVEL_DATE     datetime64[ns]\nLAST_ONSITE_TRAVEL_DAYS              int64\nREWARDS                              int64\nPRIMARY_SKILL                       object\nSECONDARY_SKILL                     object\nBASE_LOCATION_CITY                  object\nCURRENT_LOCATION_CITY               object\nHIRE_LOCATION_CITY                  object\nRESIGNATION_FLG                      int64\nBILLABILITY_STATUS                   int64\nCURRENT_RATING                     float64\nLAST_RATING                        float64\nALL_PREVIOUS_RAINGS                 object\nLATEST_HIKE_PERCENT                float64\nOFFICERCODE_DESC                    object\nGRIEVANCE_FLG                      float64\nTARGET_VALUE                         int64\nHIRE_EXIT_DATE              datetime64[ns]\nYear                                 int64\nQuarter                              int64\nMonth                              float64\nID                                  object\nPROMOTION_FLAG                       int64\nCITY_FLAG                            int64\ndtype: object\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["#Conversion of object to category \nfor i in data1:\n    if data1[i].dtype==object:\n        data1[i] = data1[i].astype('category').cat.codes\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["llisst = ['EMPLOYEE_AGE','NO_OF_LEAVES','TOTAL_REPORTEES','NO_OF_MANAGER_REPORTEES','TECHM_EXPERIENCE','TOTAL_EXPERIENCE','NO_OF_PREVIOUS_EMPLOYERS','LAST_ONSITE_TRAVEL_DAYS','TOTAL_PROMOTIONS','MANAGER_RATING','CURRENT_RATING','LAST_RATING','REWARDS','QUARTILE','TENURE_LAST_EMPLOPYER','LATEST_HIKE_PERCENT','LAST_HIKE_PERCENT','HIGHEST_EDUCATION','CITY_FLAG','Month','GRIEVANCE_FLG','BILLABILITY_STATUS']\nfor j in llisst:\n      data1[j] = data1[j].fillna(0.0).astype(int)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["data1.dtypes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: MASK_EMPLOYEEID                      int32\nEMPLOYEE_AGE                         int64\nGENDER                               int64\nNO_OF_LEAVES                         int64\nTOTAL_REPORTEES                      int64\nBAND                                 int64\nDEPARTMENT_ID                        int16\nNO_OF_MANAGER_REPORTEES              int64\nTECHM_EXPERIENCE                     int64\nTOTAL_EXPERIENCE                     int64\nLAST_HIKE_PERCENT                    int64\nMANAGER_RATING                       int64\nNO_OF_PREVIOUS_EMPLOYERS             int64\nTENURE_LAST_EMPLOPYER                int64\nHIGHEST_EDUCATION                    int64\nQUARTILE                             int64\nLAST_PROMOTION_DATE         datetime64[ns]\nTOTAL_PROMOTIONS                     int64\nMANAGER_LAST_PROMOTION      datetime64[ns]\nLAST_ONSITE_TRAVEL_DATE     datetime64[ns]\nLAST_ONSITE_TRAVEL_DAYS              int64\nREWARDS                              int64\nPRIMARY_SKILL                        int16\nSECONDARY_SKILL                       int8\nBASE_LOCATION_CITY                    int8\nCURRENT_LOCATION_CITY                 int8\nHIRE_LOCATION_CITY                    int8\nRESIGNATION_FLG                      int64\nBILLABILITY_STATUS                   int64\nCURRENT_RATING                       int64\nLAST_RATING                          int64\nALL_PREVIOUS_RAINGS                  int16\nLATEST_HIKE_PERCENT                  int64\nOFFICERCODE_DESC                      int8\nGRIEVANCE_FLG                        int64\nTARGET_VALUE                         int64\nHIRE_EXIT_DATE              datetime64[ns]\nYear                                 int64\nQuarter                              int64\nMonth                                int64\nID                                    int8\nPROMOTION_FLAG                       int64\nCITY_FLAG                            int64\ndtype: object</div>"]}}],"execution_count":45},{"cell_type":"code","source":["\ncorr = data1.corr()\nf,ax=plt.subplots(figsize=(10,10))\n#b.heatmap(corr,annot=True,linewidths=0.5,linecolor=\"green\",fmt=\".1f\",ax=ax)\nsb.heatmap(corr,annot=False,linewidths=0.5,linecolor=\"green\",fmt=\".1f\",ax=ax)\n#plt.show()\ndisplay()\n"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["'''#data1 = pd.get_dummies(data1, columns=['carrier'], prefix = ['carrier'])\ndata1 = pd.get_dummies(data1, columns=['GENDER','DEPARTMENT_ID','PRIMARY_SKILL','SECONDARY_SKILL','CURRENT_LOCATION_CITY','BASE_LOCATION_CITY','HIRE_LOCATION_CITY','RESIGNATION_FLG','BILLABILITY_STATUS','ALL_PREVIOUS_RAINGS','OFFICERCODE_DESC','GRIEVANCE_FLG'], prefix = ['GENDER','DEPARTMENT_ID','PRIMARY_SKILL','SECONDARY_SKILL','CURRENT_LOCATION_CITY','BASE_LOCATION_CITY','HIRE_LOCATION_CITY','RESIGNATION_FLG','BILLABILITY_STATUS','ALL_PREVIOUS_RAINGS','OFFICERCODE_DESC','GRIEVANCE_FLG'])\n\nprint(data1.head())\n'''"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["\n#to put target variable in last\ndft = data1.pop('TARGET_VALUE') # remove column b and store it in df1\n#df2 = df.pop('x') # remove column x and store it in df2\ndata1['TARGET_VALUE']=dft # add b series as a 'new' column.\n#df['x']=df2 # add b series as a 'new' column.\n"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["\ndft = data1.pop('HIRE_EXIT_DATE') # remove column b and store it in df1\n#df2 = df.pop('x') # remove column x and store it in df2\ndata1['HIRE_EXIT_DATE']=dft\n\n\ndft = data1.pop('LAST_PROMOTION_DATE') # remove column b and store it in df1\n#df2 = df.pop('x') # remove column x and store it in df2\ndata1['LAST_PROMOTION_DATE']=dft\n\ndft = data1.pop('MANAGER_LAST_PROMOTION') # remove column b and store it in df1\n#df2 = df.pop('x') # remove column x and store it in df2\ndata1['MANAGER_LAST_PROMOTION']=dft\n\n\ndft = data1.pop('LAST_ONSITE_TRAVEL_DATE') # remove column b and store it in df1\n#df2 = df.pop('x') # remove column x and store it in df2\ndata1['LAST_ONSITE_TRAVEL_DATE']=dft\n\n"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["remove = ['LAST_ONSITE_TRAVEL_DATE','MANAGER_LAST_PROMOTION','LAST_PROMOTION_DATE','HIRE_EXIT_DATE','TARGET_VALUE']\ndata1.drop(remove, axis=1, inplace=True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["'''import pandas as pd\ndata1.to_pickle('preprocessed.pkl')    #to save the dataframe, df to 123.pkl\n'''"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["'''import pandas as pd\ndata1.to_pickle('test_valid.pkl')  '''"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"markdown","source":["#PRE processing completed"],"metadata":{}},{"cell_type":"code","source":["data1.dtypes"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["data1.shape"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["'''\n\n#features = data.iloc[:,[1,3,4,7,8,9,10,12,13,16,17,18,29]]\n#target = data.iloc[:,]\n\nfeatures = data1.iloc[:,0:39]\n#target = data1.iloc[:,-1]\n#splitting the dataset into training and testing\n\n'''"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["'''feature_train,feature_test,target_train, target_test  = train_test_split(features,target,test_size=0.2,random_state=42)\nsc = StandardScaler()\nfeature_train = sc.fit_transform(feature_train)\nfeature_test = sc.transform(feature_test)\n'''"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":["#LSTM"],"metadata":{}},{"cell_type":"code","source":["train_set = data1.iloc[:, 1:39].values"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = sc.fit_transform(train_set)"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":[" features.info()"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":["#LSTM END"],"metadata":{}},{"cell_type":"code","source":["'''We will use three methods for feature selection:\n\nRemove collinear features\nRemove features with greater than a threshold percentage of missing values\nKeep only the most relevant features using feature importances from a model'''\n#Identify Correlated Variables\n# Threshold for removing correlated variables\nthreshold = 90\n\n# Absolute value correlation matrix\ncorr_matrix = (features.corr().abs())*100\ncorr_matrix.head(30)"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))\nprint(to_drop)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["features = features.drop(['TOTAL_EXPERIENCE', 'CURRENT_LOCATION_CITY', 'HIRE_LOCATION_CITY'], axis=1)\n#target = target\n#df = pd.DataFrame.drop(['Meter ID', 'abc'], axis=1)\n\nprint('Training shape: ', features.shape)\nprint('Testing shape: ', target.shape)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["#model.save('Minst_Lstm.model')"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["\n# Basic statistics of categorical features\nllist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nfor i in llist:\n  print(i.describe(include=[np.object]))\n#cat_col_names = data.select_dtypes(include=[np.object]).columns.tolist() # Get categorical feature names\n#cat_col_names"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["#Attrition Target Variable Distribution\nlllist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nfor i in lllist:\n  attrition_freq = i[['TARGET_VALUE']].apply(lambda x: x.value_counts())\n  attrition_freq['frequency_percent'] = round((100 * attrition_freq / attrition_freq.sum()),2)\n\n  print(attrition_freq)\n"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["def distribution(variable):\n  for i in llist:\n      print(i[variable].value_counts(),(i[i.TARGET_VALUE=='I'][variable].value_counts()*100)/i[variable].value_counts(),i[i.TARGET_VALUE=='I'][variable].value_counts())"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["distribution('DEPARTMENT_ID')"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["llist = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nfor i in llist:\n  print(distribution('OFFICERCODE_DESC'))"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":[" \"\"\"To understand how each features are impacting the attrition indicator, we need to first handle the null / missing values, otherwise our observations might not be accurate and will lead to wrong conclusions.\n\"\"\"\nfor i in llist:\n    null_feat_df = pd.DataFrame()\n    null_feat_df['Null Count'] = i.isnull().sum().sort_values(ascending=False)\n    null_feat_df['Null Pct'] = null_feat_df['Null Count'] / float(len(i))\n\n    null_feat_df = null_feat_df[null_feat_df['Null Pct'] > 0]\n\n\n    total_null_feats = null_feat_df.shape[0]\n    null_feat_names = null_feat_df.index\n    print('Total number of features having null values: ', total_null_feats)\n    del null_feat_df"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["#filling with 0\nfor i in llist:\n    i[\"LATEST_HIKE_PERCENT\"].fillna(\"0\", inplace = True) \n    i[\"LAST_HIKE_PERCENT\"].fillna(\"0\", inplace = True)\n\n    i['EMPLOYEE_AGE'].fillna(i['EMPLOYEE_AGE'].mode()[0], inplace=True) \n#EMPLOYEE_AGE "],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["\nplt.figure(1) \nplt.subplot(221) \ndata['GENDER'].value_counts(normalize=True).plot.bar(figsize=(20,10), title= 'Gender') \nplt.subplot(222) \ndata['BAND'].value_counts(normalize=True).plot.bar(title= 'Band') \nplt.subplot(223) \ndata['REWARDS'].value_counts(normalize=True).plot.bar(title= 'REWARDS') \nplt.subplot(224) \n#plt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["# Segregating data set based on Attrition value\n\n#Attrition across Job Roles\nfig, ax6 = plt.subplots(1,2, figsize=(24,10))\nattr_yes = data[data.TARGET_VALUE=='I'] #subset with Attrition = Yes\nattr_no = data[data.TARGET_VALUE=='A'] ##subset with Attrition = No\nsb.countplot(x='BAND', hue='GENDER', data = attr_yes, palette=\"Set3\", ax = ax6[1])\nsb.countplot(x='BILLABILITY_STATUS', hue='GENDER', data = attr_yes,palette=\"Set3\", ax = ax6[0])\nplt.show()\ndisplay()\n    "],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["#\ndef plot_count(feature, title,size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(data))\n    g = sb.countplot(data[feature], order = data[feature].value_counts(normalize=True).index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show()   \n    display()"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["plot_count('CURRENT_RATING','current rating')"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["#\nplt.figure(figsize=(15, 8))\ncols = ['LAST_ONSITE_TRAVEL_DAYS', 'REWARDS', 'TOTAL_PROMOTIONS', 'TENURE_LAST_EMPLOPYER', 'NO_OF_PREVIOUS_EMPLOYERS']\nuniques = [len(data[col].unique()) for col in cols]\nsb.set(font_scale=1.2)\nsb.color_palette(\"Blues\")\nax = sb.barplot(cols, uniques,log=True)\nax.set(xlabel='Feature', ylabel='log(unique count)', title='Number of unique values per feature')\nfor p, uniq in zip(ax.patches, uniques):\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height + 10,\n            uniq,\n            ha=\"center\") \n# for col, uniq in zip(cols, uniques):\n#     ax.text(col, uniq, uniq, color='black', ha=\"center\")\ndisplay()"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["def divisionplot(variable):\n  var=pd.crosstab(data[variable],data['QUARTILE'])\n  var.div(var.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=False, figsize = (10,4)) \n  #plt.show()\n  display()"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["\ndivisionplot('BAND')"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["\nsb.jointplot(x=\"TOTAL_PROMOTIONS\", y=\"TOTAL_EXPERIENCE\", data=data,  ratio=3, color=\"r\")\nplt.show()\ndisplay()\n\n"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["#main_data = fd4.copy()\nlistdf = [fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nfor i in listdf:\n  print(i['CURRENT_RATING'].value_counts() , i['CURRENT_RATING'][i['TARGET_VALUE'] == 'I'].value_counts())\n  #print(i['CURRENT_RATING'][i['TARGET_VALUE'] == 'I'].value_counts())\n  "],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["#LAST_RATING,CURRENT_RATING\nfor i in listdf:\n  freq = i[['CURRENT_RATING']].apply(lambda x: x.value_counts())\n  attr_yes_rating =i[['CURRENT_RATING']][i['TARGET_VALUE'] == 'I'].apply(lambda x: x.value_counts()) \n  freq['frequency_percent'] = round((100 * attr_yes_rating / freq.sum()),2)\n  #display()\n  print(freq)\n"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"code","source":["data['AGE_Interval'] = pd.cut(data['EMPLOYEE_AGE'], 6, labels=['19-25','25-35', '35-45', '45-55', '55-65','65+'])"],"metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":["\nage=pd.DataFrame(data.groupby(\"AGE_Interval\")[[\"TOTAL_REPORTEES\",\"NO_OF_LEAVES\",\"NO_OF_MANAGER_REPORTEES\",\"TECHM_EXPERIENCE\",\"TOTAL_EXPERIENCE\",\"LAST_HIKE_PERCENT\",\"NO_OF_PREVIOUS_EMPLOYERS\",\"TENURE_LAST_EMPLOPYER\",\"TOTAL_PROMOTIONS\",\"LAST_ONSITE_TRAVEL_DAYS\",\"REWARDS\",\"LATEST_HIKE_PERCENT\",\"HIGHEST_EDUCATION\"]].mean())\nage[\"Count\"]=data.AGE_Interval.value_counts(dropna=False)\nage.reset_index(level=0, inplace=True)\nage.head()"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":["plt.figure(figsize=(6,6))\nax=sb.barplot(x=age.AGE_Interval,y=age.Count)\nplt.xticks(rotation=90)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Counts\")\nplt.title(\"Age Counts\")\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"code","source":["\ndata['AGE_Interval'].value_counts()"],"metadata":{},"outputs":[],"execution_count":89},{"cell_type":"code","source":["plt.figure(figsize=(6,6))\nax=sb.barplot(x=age.AGE_Interval,y=age.TOTAL_PROMOTIONS,palette = sb.cubehelix_palette(len(age.index)))\nplt.xticks(rotation=90)\nplt.xlabel(\"Age\")\nplt.ylabel(\"TOTAL_PROMOTIONS\")\nplt.title(\"TOTAL_PROMOTIONS According to Age\")\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"code","source":["\"\"\"\n\"\"\"\nlabels=data.AGE_Interval.value_counts().index\n# colors=[\"olive\",\"orange\",\"hotpink\",\"slateblue\",\"y\",\"lime\"]\n#explode=[0,0,0,0,0,0]\nsizes=(data[data.TARGET_VALUE=='I'].AGE_Interval.value_counts()*100)/data.AGE_Interval.value_counts().values\nplt.figure(figsize=(7,7))\nplt.pie(sizes,labels=labels,autopct=\"%1.1f%%\")\nplt.title(\"AGE interval Counts\",color=\"saddlebrown\",fontsize=15)\ndisplay()\n"],"metadata":{},"outputs":[],"execution_count":91},{"cell_type":"code","source":["age1=pd.DataFrame(data.groupby(\"EMPLOYEE_AGE\")[[\"TOTAL_REPORTEES\",\"NO_OF_LEAVES\",\"NO_OF_MANAGER_REPORTEES\",\"TECHM_EXPERIENCE\",\"TOTAL_EXPERIENCE\",\"LAST_HIKE_PERCENT\",\"NO_OF_PREVIOUS_EMPLOYERS\",\"TENURE_LAST_EMPLOPYER\",\"TOTAL_PROMOTIONS\",\"LAST_ONSITE_TRAVEL_DAYS\",\"REWARDS\",\"LATEST_HIKE_PERCENT\",\"HIGHEST_EDUCATION\"]].mean())\nage1[\"Count\"]=data.EMPLOYEE_AGE.value_counts(dropna=False)\nage1.reset_index(level=0, inplace=True)\nage1.head()"],"metadata":{},"outputs":[],"execution_count":92},{"cell_type":"code","source":["agenorm=age1.apply(lambda x: x/max(x))\nagenorm.head()"],"metadata":{},"outputs":[],"execution_count":93},{"cell_type":"code","source":["ageb=data.EMPLOYEE_AGE.value_counts().index\nf,ax=plt.subplots(figsize=(15,15))\nsb.pointplot(y=agenorm.LAST_HIKE_PERCENT,x=ageb,color=\"purple\",alpha=0.8)\nsb.pointplot(y=agenorm.TOTAL_PROMOTIONS,x=ageb,color=\"sandybrown\",alpha=0.8)\nplt.text(5,0.65,\"LAST_HIKE_PERCENT\",color=\"purple\",fontsize=15,style=\"italic\")\nplt.text(5,0.63,\"TOTAL_PROMOTIONS\",color=\"sandybrown\",fontsize=15,style=\"italic\")\nplt.xlabel(\"Age\",fontsize=15,color=\"darkred\")\nplt.ylabel(\"Values\",fontsize=15,color=\"darkred\")\nplt.title(\"LAST_HIKE_PERCENTe VS JTOTAL_PROMOTIONS\",fontsize=15,color=\"darkred\")\nplt.grid()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":94},{"cell_type":"code","source":["ageb=data.EMPLOYEE_AGE.value_counts().index\nf,ax=plt.subplots(figsize=(15,15))\nsb.pointplot(y=agenorm.LATEST_HIKE_PERCENT,x=ageb,color=\"purple\",alpha=0.8)\nsb.pointplot(y=agenorm.TOTAL_PROMOTIONS,x=ageb,color=\"sandybrown\",alpha=0.8)\nplt.text(5,0.65,\"LATEST_HIKE_PERCENT\",color=\"purple\",fontsize=15,style=\"italic\")\nplt.text(5,0.63,\"TOTAL_PROMOTIONS\",color=\"sandybrown\",fontsize=15,style=\"italic\")\nplt.xlabel(\"Age\",fontsize=15,color=\"darkred\")\nplt.ylabel(\"Values\",fontsize=15,color=\"darkred\")\nplt.title(\"LAST_HIKE_PERCENTe VS JTOTAL_PROMOTIONS\",fontsize=15,color=\"darkred\")\nplt.grid()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":95},{"cell_type":"code","source":["f,ax = plt.subplots(figsize = (15,10))\nsb.kdeplot(agenorm.REWARDS,agenorm.LAST_ONSITE_TRAVEL_DAYS,shade=True,cut=1)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":96},{"cell_type":"code","source":["f,ax = plt.subplots(figsize = (15,10))\nsb.kdeplot(agenorm.TOTAL_PROMOTIONS,agenorm.LAST_ONSITE_TRAVEL_DAYS,shade=True,cut=1)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":97},{"cell_type":"code","source":["promotions=pd.DataFrame(data.groupby(\"BAND\").TOTAL_PROMOTIONS.mean().sort_values(ascending=False))\nplt.figure(figsize=(5,5))\nax=sb.barplot(x=promotions.index,y=promotions.TOTAL_PROMOTIONS)\nplt.xticks(rotation=90)\nplt.xlabel(\"BAND\")\nplt.ylabel(\"TOTAL_PROMOTIONS\")\nplt.title(\"BAND with TOTAL_PROMOTIONS\")\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":98},{"cell_type":"code","source":["band=pd.DataFrame(data.groupby(\"BAND\")[\"EMPLOYEE_AGE\",\"NO_OF_LEAVES\",\"NO_OF_PREVIOUS_EMPLOYERS\",\"NO_OF_MANAGER_REPORTEES\",\"LAST_ONSITE_TRAVEL_DAYS\",\"LATEST_HIKE_PERCENT\",\"LAST_HIKE_PERCENT\",\"NO_OF_MANAGER_REPORTEES\",\"TENURE_LAST_EMPLOPYER\",\"TECHM_EXPERIENCE\",\"TOTAL_EXPERIENCE\"].mean())\nband"],"metadata":{},"outputs":[],"execution_count":99},{"cell_type":"code","source":["f,ax = plt.subplots(figsize = (9,10))\nsb.barplot(x=band.LATEST_HIKE_PERCENT,y=band.index,color='green',alpha = 0.5,label='LATEST_HIKE_PERCENT' )\nsb.barplot(x=band.LAST_ONSITE_TRAVEL_DAYS,y=band.index,color='blue',alpha = 0.7,label='LAST_ONSITE_TRAVEL_DAYS')\nsb.barplot(x=band.TECHM_EXPERIENCE,y=band.index,color='cyan',alpha = 0.6,label='Years At Company')\nsb.barplot(x=band.NO_OF_PREVIOUS_EMPLOYERS,y=band.index,color='yellow',alpha = 0.6,label='NO_OF_PREVIOUS_EMPLOYERS')\nsb.barplot(x=band.NO_OF_LEAVES,y=band.index,color='red',alpha = 0.6,label='NO_OF_LEAVES')\n\nax.legend(loc='right',frameon = True)     \nax.set(xlabel='Values', ylabel='band',title = \"band with Different Features\")\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":100},{"cell_type":"code","source":["g = sb.pairplot(data, vars=[\"TOTAL_PROMOTIONS\", \"REWARDS\"],hue=\"BAND\",size=5)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":101},{"cell_type":"code","source":["\nf,ax = plt.subplots(figsize = (5,5))\nsb.boxplot(x=\"GENDER\",y=\"EMPLOYEE_AGE\",hue=\"QUARTILE\",data=data,palette=\"Paired\")\ndisplay()"],"metadata":{},"outputs":[],"execution_count":102},{"cell_type":"code","source":["f,ax = plt.subplots(figsize = (15,10))\nax.legend(frameon=False, loc='lower center', ncol=2)\n\nsb.boxplot(x=\"GENDER\",y=\"EMPLOYEE_AGE\",hue=\"BAND\" ,data=data,palette=\"hls\")\ndisplay()"],"metadata":{},"outputs":[],"execution_count":103},{"cell_type":"code","source":["\nf,ax = plt.subplots(figsize = (5,5))\nsb.pointplot(x=\"GENDER\", y=\"TECHM_EXPERIENCE\", hue=\"TARGET_VALUE\", data=data,\n              palette={\"I\": \"blue\", \"A\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);\ndisplay()\n## Inference\n# Males and Females within the ranges for 'TotalWorkingYears' of 11 to 13 are less likely to quit"],"metadata":{},"outputs":[],"execution_count":104},{"cell_type":"code","source":["data['TECHM_Interval'] = pd.cut(data['TECHM_EXPERIENCE'], 6, labels=['0-5','5-10', '10-15', '15-20', '20-25','25+'])"],"metadata":{},"outputs":[],"execution_count":105},{"cell_type":"code","source":["f,ax = plt.subplots(figsize = (5,5))\n#plt.subplots(figsize=(15,5))\nsb.countplot(data.TECHM_Interval)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":106},{"cell_type":"code","source":["data['HIGHEST_EDUCATION'].value_counts()\n\n\n#print(data['HIGHEST_EDUCATION'].value_counts())"],"metadata":{},"outputs":[],"execution_count":107},{"cell_type":"code","source":["data1"],"metadata":{},"outputs":[],"execution_count":108},{"cell_type":"code","source":["data1['EDUCATION_CATEGORIES'].value_counts()"],"metadata":{},"outputs":[],"execution_count":109},{"cell_type":"code","source":["f,ax = plt.subplots(figsize = (11,5))\n#plt.subplots(figsize=(15,5))\nsb.countplot(data.EDUCATION_CATEGORIES)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":110},{"cell_type":"code","source":["labels=data.EDUCATION_CATEGORIES.value_counts().index\ncolors=[\"olive\",\"orange\",\"hotpink\",\"slateblue\",\"y\",\"lime\",\"b\"]\nexplode=[1,0,0,0,1,1]\nsizes=data.EDUCATION_CATEGORIES.value_counts() \nplt.figure(figsize=(7,7))\nplt.pie(sizes,labels=labels,colors=colors,autopct=\"%1.1f%%\")\nplt.title(\"Education Field Counts\",color=\"saddlebrown\",fontsize=15)\ndisplay()\n"],"metadata":{},"outputs":[],"execution_count":111},{"cell_type":"code","source":["#LAST_RATING,CURRENT_RATING\nfor i in listdf:\n  i['LeavesInterval'] = pd.cut(i['NO_OF_LEAVES'][i['NO_OF_LEAVES']<50], 5, labels=['<10', '<20', '<30', '<40','<50+'])\n  freq = i[['LeavesInterval']].apply(lambda x: x.value_counts())\n  attr_yes_rating =i[['LeavesInterval']][i['TARGET_VALUE'] == 'I'].apply(lambda x: x.value_counts()) \n  freq['frequency_percent'] = round((100 * attr_yes_rating / freq.sum()),2)\n  #display()\n  print(freq)"],"metadata":{},"outputs":[],"execution_count":112},{"cell_type":"code","source":["#data['LeavesInterval'].value_counts()\ndata['LeavesInterval'] = pd.cut(i['NO_OF_LEAVES'][i['NO_OF_LEAVES']<50], 5, labels=['<10', '<20', '<30', '<40','<50+'])"],"metadata":{},"outputs":[],"execution_count":113},{"cell_type":"code","source":["#LAST_RATING,CURRENT_RATING\nfor i in listdf:\n  freq = i[['DEPARTMENT_ID']].apply(lambda x: x.value_counts())\n  attr_yes_rating =i[['DEPARTMENT_ID']][i['TARGET_VALUE'] == 'I'].apply(lambda x: x.value_counts()) \n  freq['frequency_percent'] = round((100 * attr_yes_rating / freq.sum()),2)\n  #display()\n  #print(freq)\n  print(freq[\"frequency_percent\"].max())"],"metadata":{},"outputs":[],"execution_count":114},{"cell_type":"code","source":["# library and dataset\n#import seaborn as sns\n#df = sns.load_dataset('iris')\nf,ax = plt.subplots(figsize = (15,10))\n# plot of 2 variables\nsb.kdeplot(data['TOTAL_REPORTEES'], shade=True, color=\"r\")\nsb.kdeplot(data['NO_OF_MANAGER_REPORTEES'], shade=True, color=\"b\")\n#sns.plt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":115},{"cell_type":"code","source":["# library and dataset\n#import seaborn as sns\n#df = sns.load_dataset('iris')\nf,ax = plt.subplots(figsize = (5,5))\n# plot of 2 variables\nsb.kdeplot(data['TOTAL_PROMOTIONS'], shade=True, color=\"r\")\nsb.kdeplot(data['REWARDS'], shade=True, color=\"b\")\n#sns.plt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":116},{"cell_type":"code","source":["data['HIRE_LOCATION_CITY'].value_counts()"],"metadata":{},"outputs":[],"execution_count":117},{"cell_type":"code","source":["idx1 = pd.Index(data.CURRENT_LOCATION_CITY)\nidx2 = pd.Index(data.BASE_LOCATION_CITY)\nidx3 = pd.Index(data.HIRE_LOCATION_CITY)\n#main_data['unique'] = idx1.difference(idx2).values\nprint(idx1.difference(idx2).values)\nprint(idx2.difference(idx1).values)\nprint(idx3.difference(idx1).values)\n#print(idx3.difference(idx2).values)\n#array([3, 6])"],"metadata":{},"outputs":[],"execution_count":118},{"cell_type":"code","source":["#LAST_RATING,CURRENT_RATING\nfor i in listdf:\n  freq = i[['HIRE_LOCATION_CITY']].apply(lambda x: x.value_counts())\n  attr_yes_rating =i[['HIRE_LOCATION_CITY']][i['TARGET_VALUE'] == 'I'].apply(lambda x: x.value_counts()) \n  freq['frequency_percent'] = round((100 * attr_yes_rating / freq.sum()),2)\n  #display()\n  print(freq)"],"metadata":{},"outputs":[],"execution_count":119},{"cell_type":"code","source":["#LAST_RATING,CURRENT_RATING\nfor i in listdf:\n  freq = i[['HIRE_EXIT_DATE']].apply(lambda x: x.value_counts())\n  attr_yes_rating =i[['HIRE_EXIT_DATE']][i['TARGET_VALUE'] == 'I'].apply(lambda x: x.value_counts()) \n  freq['frequency_percent'] = round((100 * attr_yes_rating / freq.sum()),2)\n  #display()\n  print(freq)\n  \n  \n  "],"metadata":{},"outputs":[],"execution_count":120},{"cell_type":"code","source":["data.columns"],"metadata":{},"outputs":[],"execution_count":121},{"cell_type":"code","source":["features=['LeavesInterval','TECHM_Interval','CURRENT_RATING','AGE_Interval', 'TOTAL_PROMOTIONS','DEPARTMENT_ID ','QUARTILE']\nfig=plt.subplots(figsize=(10,15))\nfor i, j in enumerate(features):\n    plt.subplot(4, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sb.countplot(x=j,data = data)\n    plt.xticks(rotation=90)\n    plt.title(\"No. of employee\")\n    display()"],"metadata":{},"outputs":[],"execution_count":122},{"cell_type":"code","source":["# pie chart of workers\nlabels = ['M', 'F']\nsizes = [data['GENDER'].value_counts()[0],\n         data['GENDER'].value_counts()[1]\n        ]\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\nax1.axis('equal')\nplt.title('Gender Pie Chart', fontsize=20)\nplt.show()\ndisplay()\n\n## Inference\n# Proportion of male is higher than female associates"],"metadata":{},"outputs":[],"execution_count":123},{"cell_type":"code","source":["fig=plt.subplots(figsize=(5,5))\nsb.factorplot(data=data,y='TOTAL_PROMOTIONS',x='BAND',size=7,aspect=2,kind='point')\ndisplay()\n"],"metadata":{},"outputs":[],"execution_count":124},{"cell_type":"code","source":["x"],"metadata":{},"outputs":[],"execution_count":125},{"cell_type":"code","source":["\"\"\"\n# Plotting the KDEplots\nf, axes = plt.subplots(3, 3, figsize=(10, 8), \n                       sharex=False, sharey=False)\n\n# Defining our colormap scheme\ns = np.linspace(0, 3, 7)\ncmap = sb.cubehelix_palette(start=0.0, light=1, as_cmap=True)\n\n# Generate and plot\nx = data['EMPLOYEE_AGE'].values\ny = data['TECHM_EXPERIENCE'].values\nsb.kdeplot(x, y, cmap=cmap, shade=True, cut=5, ax=axes[0,0])\naxes[0,0].set( title = 'Age Vs TechMExperience')\n#display()\ncmap = sb.cubehelix_palette(start=0.333333333333, light=1, as_cmap=True)\n\n# Generate and plot\nx = data['EMPLOYEE_AGE'].values\ny = data['NO_OF_LEAVES'].values\nsb.kdeplot(x, y, cmap=cmap, shade=True, ax=axes[0,1])\naxes[0,1].set( title = 'Age Vs no_of_leaves')\n#display()\n\ncmap = sb.cubehelix_palette(start=0.666666666667, light=1, as_cmap=True)\n# Generate and plot\nx = data['NO_OF_PREVIOUS_EMPLOYERS'].values\ny = data['EMPLOYEE_AGE'].values\nsb.kdeplot(x, y, cmap=cmap, shade=True, ax=axes[0,2])\naxes[0,2].set( title = 'No_of_prev_employers Vs Age')\ndisplay()\n'''\ncmap = sns.cubehelix_palette(start=1.0, light=1, as_cmap=True)\n# Generate and plot\nx = attrition['DailyRate'].values\ny = attrition['DistanceFromHome'].values\nsns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[1,0])\naxes[1,0].set( title = 'Daily Rate against DistancefromHome')\n\ncmap = sns.cubehelix_palette(start=1.333333333333, light=1, as_cmap=True)\n# Generate and plot\nx = attrition['DailyRate'].values\ny = attrition['JobSatisfaction'].values\nsns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[1,1])\naxes[1,1].set( title = 'Daily Rate against Job satisfaction')\n\ncmap = sns.cubehelix_palette(start=1.666666666667, light=1, as_cmap=True)\n# Generate and plot\nx = attrition['YearsAtCompany'].values\ny = attrition['JobSatisfaction'].values\nsns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[1,2])\naxes[1,2].set( title = 'Daily Rate against distance')\n\ncmap = sns.cubehelix_palette(start=2.0, light=1, as_cmap=True)\n# Generate and plot\nx = attrition['YearsAtCompany'].values\ny = attrition['DailyRate'].values\nsns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[2,0])\naxes[2,0].set( title = 'Years at company against Daily Rate')\n\ncmap = sns.cubehelix_palette(start=2.333333333333, light=1, as_cmap=True)\n# Generate and plot\nx = attrition['RelationshipSatisfaction'].values\ny = attrition['YearsWithCurrManager'].values\nsns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[2,1])\naxes[2,1].set( title = 'Relationship Satisfaction vs years with manager')\n\ncmap = sns.cubehelix_palette(start=2.666666666667, light=1, as_cmap=True)\n# Generate and plot\nx = attrition['WorkLifeBalance'].values\ny = attrition['JobSatisfaction'].values\nsns.kdeplot(x, y, cmap=cmap, shade=True,  ax=axes[2,2])\naxes[2,2].set( title = 'WorklifeBalance against Satisfaction')\nf.tight_layout()\ndispaly()\n'''\n\"\"\""],"metadata":{},"outputs":[],"execution_count":126},{"cell_type":"code","source":["\"\"\"\ntrain_small = data# train.sample(frac=0.2).copy() # not small for now\nfig, ax = plt.subplots(1, 2, figsize=(16, 8))\nsb.kdeplot(train_small.loc[data['BILLABILITY_STATUS'] == 'N', 'EMPLOYEE_AGE'], ax=ax[0], label='NoPay(0)')\nsb.kdeplot(train_small.loc[data['BILLABILITY_STATUS'] == 'Y', 'EMPLOYEE_AGE'], ax=ax[0], label='HasPay(1)')\n\n#\\train_small.loc[data['HasDetections'] == 0, 'DefaultBrowsersIdentifier'].hist(ax=ax[1])\n#train_small.loc[train['HasDetections'] == 1, 'DefaultBrowsersIdentifier'].hist(ax=ax[1])\n#ax[1].legend(['NoDetection(0)', 'HasDetection(1)'])\n\nplt.show()\ndisplay()\n\"\"\"\n'''\n'''"],"metadata":{},"outputs":[],"execution_count":127},{"cell_type":"code","source":["\"\"\"\n'''\n# Segregating data set based on Attrition value\nattr_yes = data[data.TARGET_VALUE=='I'] #subset with Attrition = Yes\nattr_no = data[data.TARGET_VALUE=='A'] ##subset with Attrition = No\n'''\nattrition = data[(data['TARGET_VALUE'] == 'A' )]\nno_attrition = data[(data['TARGET_VALUE'] == 'I')]\n'''\n# Segregating data set based on Attrition value\nattr_yes = data[data.TARGET_VALUE=='I'] #subset with Attrition = Yes\nattr_no = data[data.TARGET_VALUE=='A'] ##subset with Attrition = No\n#Add columns to store discrete variables for Salary range and alcohol levels\n#Adding discrete valriables\ndata['LeavesInterval'] = pd.cut(data['NO_OF_LEAVES'], 5, labels=['<9', '<15', '<24', '<32', '<33+'])\ndata['TechMExpLvl'] = pd.cut(data['TECHM_EXPERIENCE'], 5, labels=['lvl1', 'lvl2', 'lvl3', 'lvl4', 'lvl5'])\ndata['traveldate'] = pd.cut(data['LAST_ONSITE_TRAVEL_DAYS'], 5, labels=['0to3', '3to6', '6to9', '9to12', '12+'])\n\n\n\n#Factor Plot\nsb.factorplot(x =   'TARGET_VALUE',     # Categorical\n               y =   'NO_OF_LEAVES',          # Continuous\n               hue = 'DEPARTMENT_ID',   # Categorical\n               col = 'LeavesInterval',   # Categorical for graph columns\n               col_wrap=3,           # Wrap facet after two axes\n               kind = 'box',\n               data = data)\nplt.show()\ndisplay()\n\n\n# Attrition count across Daily Rate, Years in company, Years since last promotion and level of stock options\nfig, ax2 = plt.subplots(2,2, figsize=(10,10))\nsb.countplot(x='LeavesInterval', data=attr_yes, ax = ax2[0,0])\nsb.countplot(x='TechMExpLvl', data=attr_yes, ax = ax2[0,1])\nsb.countplot(x='traveldate', data=attr_yes, ax = ax2[1,0])\n#sb.countplot(x='StockOptionLevel', data=attr_yes, ax = ax2[1,1])\nplt.show()\ndisplay()\n'''\n\"\"\"\n\"\"\"\n#Count Plot\n# Attrition across Education level and corresponding percentage across the total number of employees\ntotal = data.shape[0] \nhrfig = sb.countplot(x='HIGHEST_EDUCATION', hue = 'TARGET_VALUE', data = data)\n#Above graph showcases the percentages of the employees across Education levels and corresponding attri\nfor p in hrfig.patches:\n    height = p.get_height()\n    hrfig.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}'.format(height*100/total),\n            ha=\"center\") \nplt.show()\ndisplay()\n\"\"\"\n"],"metadata":{},"outputs":[],"execution_count":128},{"cell_type":"code","source":["'''from datetime import date\nfrom datetime import datetime\n\ndt = datetime.combine(date.today(), datetime.min.time())\nprint(dt)'''"],"metadata":{},"outputs":[],"execution_count":129},{"cell_type":"code","source":["\"\"\"\n# Attrition distribution bar plot\n\nplot = attrition_freq[['frequency_percent']].plot(kind=\"bar\");\nplot.set_title(\"Attrition Distribution\", fontsize=40);\nplot.grid(color='lightgray', alpha=0.5);\ndisplay()\n\"\"\"\n\"\"\"Just by a quick inspection of the counts of the number of 'Yes' and 'No' in the target variable tells us that there is quite a large skew in target variable.\nTherefore we have to keep in mind that there is quite a big imbalance in our target variable. Many statistical techniques have been put forth to treat imbalances in data (oversampling or undersampling).\nIn this notebook, I will use an oversampling technique known as SMOTE to treat this imbalance.\nWe will see the prediction model with and without SMOTE treatment for imbalance class issue.\"\"\"\n"],"metadata":{},"outputs":[],"execution_count":130},{"cell_type":"code","source":["\"\"\"\n#Step 4 - Feature Engineering\nFeature engineering is one aspect which provided a huge impact on the outcome rather than the model. Here, we try at creating new features with the existing variables we have based on my assumptions.\n\nStep 4.1 - Addition of New Features\nTenure per job: Usually, people who have worked with many companies but for small periods at every organization tend to leave early as they always need a change of Organization to keep them going.\nYears without Change: For any person, a change either in role or job level or responsibility is needed to keep the work exciting to continue. We create a variable to see how many years it has been for an employee without any sort of change using Promotion, Role and Job Change as a metric to cover different variants of change.\nCompensation Ratio: Compa Ratio is the ratio of the actual pay of an Employee to the midpoint of a salary range. The salary range can be that of his/her department or organization or role. The benchmark numbers can be a organizations pay or Industry average.\n\n\n\"\"\"\nemp_proc_df = data.copy() # Copy cleaned dataset for feature engineering\n\nemp_proc_df['TenurePerJob'] = 0\n\nfor i in range(0, len(emp_proc_df)):\n    if emp_proc_df.loc[i,'NO_OF_PREVIOUS_EMPLOYERS'] > 0:\n        emp_proc_df.loc[i,'TenurePerJob'] = emp_proc_df.loc[i,'TOTAL_EXPERIENCE'] / emp_proc_df.loc[i,'NO_OF_PREVIOUS_EMPLOYERS']\n\"\"\"\nemp_proc_df['YearWithoutChange1'] = emp_proc_df['YearsInCurrentRole'] - emp_proc_df['YearsSinceLastPromotion']\nemp_proc_df['YearWithoutChange2'] = emp_proc_df['TotalWorkingYears'] - emp_proc_df['YearsSinceLastPromotion']\n\nmonthly_income_median = np.median(emp_proc_df['MonthlyIncome'])\nemp_proc_df['CompRatioOverall'] = emp_proc_df['MonthlyIncome'] / monthly_income_median\n\nprint('Dataset dimension: {} rows, {} columns'.format(emp_proc_df.shape[0], emp_proc_df.shape[1]))\n\"\"\"\n\n\n\n\n\n\n\n\n\nfull_col_names = emp_proc_df.columns.tolist()\nnum_col_names = emp_proc_df.select_dtypes(include=[np.int64,np.float64]).columns.tolist() # Get numerical feature names\n\n# Preparing list of ordered categorical features\nfor i in emp_proc_df:\n    if emp_proc_df[i].dtype==object:\n        num_cat_col_names = emp_proc_df[i]\n#num_cat_col_names = ['DEPARTMENT_ID', 'TARGET_VALUE', 'OFFICERCODE_DESC', 'ALL_PREVIOUS_RAINGS', 'JobSatisfaction',\n                     #'PerformanceRating', 'RelationshipSatisfaction', 'WorkLifeBalance', 'StockOptionLevel']\n\ntarget = ['TARGET_VALUE']\n\nnum_col_names = list(set(num_col_names) - set(num_cat_col_names)) # Numerical features w/o Ordered Categorical features\ncat_col_names = list(set(full_col_names) - set(num_col_names) - set(target)) # Categorical & Ordered Categorical features\n\nprint('Total number of numerical features: ', len(num_col_names))\nprint('Total number of categorical & ordered categorical features: ', len(cat_col_names))\ncat_emp_df = emp_proc_df[cat_col_names]\nnum_emp_df = emp_proc_df[num_col_names]\n\n\n\n\n\n\n\n\n\n#Transform Numerical Features\n#In order to fix the skewness, lets take the log for all numerical features with an absolute skew greater than 80% (Note: log+1, to avoid division by zero issues).\n\n# Let's create dummy variables for each categorical attribute for training our calssification model\nfor col in num_col_names:\n    if num_emp_df[col].skew() > 0.80:\n        num_emp_df[col] = np.log1p(num_emp_df[col])\n\nnum_emp_df.head()\n\n\n\n\n\n\"\"\" #Transform Categorical Features\nMachine Learning model works only on numerical datasets, hence, we need to transform categorical features into numerical features.\nOne of the best strategy is to convert each category value into a new column and assigns 1 or 0 (True/False) value to the column. This has the benefit of not weighting a value improperly but does have the downside of adding more columns to the data set.\nThis approach is also called as \"One Hot Encoding\". We can use Pandas feature get_dummies to achieve this transformation.\nThere is another way to handled ordered categorical feature is to give ordered value based on their definitions i.e Low-Meidum-High would be 1-2-3. We can try this approach some other time. But, this can be evaluated to check the performance of the model.\n\"\"\"\n# Let's create dummy variables for each categorical attribute for training our calssification model\nfor col in cat_col_names:\n    col_dummies = pd.get_dummies(cat_emp_df[col], prefix=col)\n    cat_emp_df = pd.concat([cat_emp_df, col_dummies], axis=1)\n\n# Use the pandas apply method to numerically encode our attrition target variable\nattrition_target = emp_proc_df['TARGET_VALUE'].map({'I':1, 'A':0})\n\n# Drop categorical feature for which dummy variables have been created\n\ncat_emp_df.drop(cat_col_names, axis=1, inplace=True)\ncat_emp_df.head()\n\n\n\n\n# Correlation of Numerical Features against Attrition\nnum_corr_df = num_emp_df[['EMPLOYEE_AGE', 'NO_OF_MANAGER_REPORTEES', 'TOTAL_REPORTEES']]\ncorr_df = pd.concat([num_corr_df, attrition_target], axis=1)\ncorr = corr_df.corr()\ndisplay()\nplt.figure(figsize = (10, 8))\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsb.axes_style(\"white\")\n#sns.heatmap(data=corr, annot=True, mask=mask, square=True, linewidths=.5, vmin=-1, vmax=1, cmap=\"YlGnBu\")\nsb.heatmap(data=corr, annot=True, square=True, linewidths=.5, vmin=-1, vmax=1, cmap=\"YlGnBu\")\nplt.show()\ndisplay()\n\n\n\n\n\n\n# Another way to check for correlation between attributes is to use Pandas scatter_matrix function,\n\nfrom pandas.plotting import scatter_matrix\n\nscatter_matrix(corr_df, figsize=(16, 10));\ndisplay()\n\n\n\n# Concat the two dataframes together columnwise\nfinal_emp_df = pd.concat([num_emp_df, cat_emp_df], axis=1)\n\nprint('Dataset dimension after treating categorical features with dummy variables: {} rows, {} columns'.format(final_emp_df.shape[0], final_emp_df.shape[1]))\nfinal_emp_df.head()\n\n\n\n\n\n\n\n\n\n\n\"\"\"\n#Model Building and Validation\nSince, we have to predict a binary class, we will be using classification models for training & predicting Employee Attrition. We need to keep in mind that our focus should be to have a better accuracy of predicting attrition i.e. Attrition = 1 which in confusion matrix will be \"True Positive\". However, we should not forget the prediction accuracy of not qualifying for attrition i.e. Attrition = 0 which will be \"True Negative\" in confusion matrix.\n\nSo, we need to focus on four parameters:\n\nAccuracy: Overall, how often is the classifier correct? i.e {(TP+TN)/Total}\nTrue Positive Rate: When it's actually yes, how often does it predict yes? default_ind = 1, {TP/Actual YES}, this is also known as \"Sensitivity\" or \"Recall\"\nPrecision: When it predicts yes, how often is it correct? i.e. {TP/(TP+FP)}\nSpecificity: When it's actually no, how often does it predict no? default_ind = 0, {TN/actual NO}\nCross Validation Score: Cross Validation is a technique which involves reserving a particular sample of a dataset on which you do not train the model. Later, you test your model on this sample before finalizing it. Do this for k folds and take mean of accuracy scores of the k fold models.\nF1 Score: This is a weighted average of the true positive rate (recall) and precision.\nROC Curve: This is a commonly used graph that summarizes the performance of a classifier over all possible thresholds. It is generated by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis) as you vary the threshold for assigning observations to a given class.\nAbove information was taken and more details can be found at https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n\nStep 5.1 - Prepare Train & Test Dataset\nThe data should be divided into train and test data. We will use train_test_split feature to divide the data and we will be using 70-30 ratio\n\"\"\"\n# Import the train_test_split method\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# Split data into train and test sets as well as for validation and testing\nX_train, X_val, y_train, y_val = train_test_split(final_emp_df, attrition_target,\n                                                  test_size= 0.30, random_state=42);\n\nprint(\"Stratified Sampling: \", len(X_train), \"train set +\", len(X_val), \"validation set\")\n\n# Stratified Splitting\n#split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n#for train_index, test_index in split.split(emp_data_proc, emp_data_proc['Gender']):\n#    strat_train_set = emp_data_proc.loc[train_index]\n#    strat_test_set = emp_data_proc.loc[test_index]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\ndef gen_model_performance(actual_target, pred_target):\n    model_conf_matrix = confusion_matrix(actual_target, pred_target)\n    model_roc_score = roc_auc_score(actual_target, pred_target)\n    model_accuracy = accuracy_score(actual_target, pred_target) * 100.0\n    \n    TP = model_conf_matrix[1][1]; TN = model_conf_matrix[0][0]; \n    FP = model_conf_matrix[0][1]; FN = model_conf_matrix[1][0];\n    sensitivity = TP / float(TP + FN) * 100.0; specificity = TN / float(TN + FP) * 100.0;\n    precision = TP / float(TP + FP) * 100.0;\n    \n    return sensitivity, specificity, model_accuracy, precision, model_roc_score\ndef evaluate_model_score(X, y, scoring='accuracy'):\n    \n    logreg_model = LogisticRegression(random_state=0)\n    logreg_cv_model = LogisticRegressionCV()\n    rfc_model = RandomForestClassifier()\n    extrees_model = ExtraTreesClassifier()\n    gboost_model = GradientBoostingClassifier()\n    dt_model = DecisionTreeClassifier()\n    aboost_model = AdaBoostClassifier()\n    gnb_model = GaussianNB()\n\n    models = [logreg_model, logreg_cv_model, dt_model, rfc_model, \n              extrees_model, gboost_model, aboost_model, gnb_model]\n    \n    model_results = pd.DataFrame(columns = [\"Model\", \"Accuracy\", \"Precision\", \"CV Score\",\n                                            \"Sensitivity\",\"Specificity\",\"ROC Score\"])\n    \n    for model in models:\n        model.fit(X, y,)\n        y_pred = model.predict(X)\n        score = cross_val_score(model, X, y, cv=5, scoring=scoring)\n        \n        sensitivity, specificity, accuracy, precision, roc_score = gen_model_performance(y, y_pred)\n    \n        scores = cross_val_score(model, X, y, cv=5)\n    \n        model_results = model_results.append({\"Model\": model.__class__.__name__,\n                              \"Accuracy\": accuracy, \"Precision\": precision,\n                              \"CV Score\": scores.mean()*100.0,\n                              \"Sensitivity\": sensitivity, \"Specificity\": specificity,\n                              \"ROC Score\": roc_score}, ignore_index=True)\n    return model_results\n \"\"\""],"metadata":{},"outputs":[],"execution_count":131},{"cell_type":"code","source":["fd1.info()"],"metadata":{},"outputs":[],"execution_count":132},{"cell_type":"code","source":["llist=[fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nfor i in llist:\n  i.CURRENT_RATING.fillna(i.LAST_RATING,inplace=True)\n  i.CURRENT_RATING.fillna(i.ALL_PREVIOUS_RAINGS.str[-1],inplace=True)"],"metadata":{},"outputs":[],"execution_count":133},{"cell_type":"code","source":["for i in range(fd1[fd1.CURRENT_RATING.isnull()].ALL_PREVIOUS_RAING.shape[0]):\n  a=fd1[fd1.CURRENT_RATING.isnull()].ALL_PREVIOUS_RAING[i]\n  print(a[-1])"],"metadata":{},"outputs":[],"execution_count":134},{"cell_type":"code","source":["llist=[fd1,fd2,fd3,fd4,fd5,fd6,fd7,fd8]\nfor i in llist:\n  i.PRIMARY_SKILL.fillna(i.SECONDARY_SKILL,inplace=True)"],"metadata":{},"outputs":[],"execution_count":135},{"cell_type":"code","source":["'''s='20170601'\ndate=pd.to_datetime(s)\ndate'''"],"metadata":{},"outputs":[],"execution_count":136},{"cell_type":"code","source":["for i in list_df:\n  i.replace(' ', np.nan, inplace=True)"],"metadata":{},"outputs":[],"execution_count":137},{"cell_type":"code","source":["da1=pd.to_datetime('20160301')\nda2=pd.to_datetime('20160601')\nfd1['PROMOTION_FLAG']=fd1.apply(lambda fd1 : 1 if fd1.LAST_PROMOTION_DATE.date()>=da1.date() and fd1.LAST_PROMOTION_DATE.date()<=da2.date()  else 0,axis=1)\nda1=pd.to_datetime('20160601')\nda2=pd.to_datetime('20160901')\nfd2['PROMOTION_FLAG']=fd2.apply(lambda fd2 : 1 if fd2.LAST_PROMOTION_DATE.date()>da1.date() and fd2.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)\nda1=pd.to_datetime('20160901')\nda2=pd.to_datetime('20161201')\nfd3['PROMOTION_FLAG']=fd3.apply(lambda fd3 : 1 if fd3.LAST_PROMOTION_DATE.date()>da1.date() and fd3.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)\nda1=pd.to_datetime('20161201')\nda2=pd.to_datetime('20170301')\nfd4['PROMOTION_FLAG']=fd4.apply(lambda fd4 : 1 if fd4.LAST_PROMOTION_DATE.date()>da1.date() and fd4.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)\nda1=pd.to_datetime('20170301')\nda2=pd.to_datetime('20170601')\nfd5['PROMOTION_FLAG']=fd5.apply(lambda fd5 : 1 if fd5.LAST_PROMOTION_DATE.date()>da1.date() and fd5.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)\nda1=pd.to_datetime('20170601')\nda2=pd.to_datetime('20170901')\nfd6['PROMOTION_FLAG']=fd6.apply(lambda fd6 : 1 if fd6.LAST_PROMOTION_DATE.date()>da1.date() and fd6.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)\nda1=pd.to_datetime('20170901')\nda2=pd.to_datetime('20171201')\nfd7['PROMOTION_FLAG']=fd7.apply(lambda fd7 : 1 if fd7.LAST_PROMOTION_DATE.date()>da1.date() and fd7.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)\nda1=pd.to_datetime('20171201')\nda2=pd.to_datetime('20180301')\nfd8['PROMOTION_FLAG']=fd8.apply(lambda fd8 : 1 if fd8.LAST_PROMOTION_DATE.date()>da1.date() and fd8.LAST_PROMOTION_DATE.date()<da2.date() else 0,axis=1)"],"metadata":{},"outputs":[],"execution_count":138},{"cell_type":"code","source":["da=datetime(2016,1,1)\n# fd1.LAST_PROMOTION_DATE.dt.date<da.date()\n# fd1.LAST_PROMOTION_DATE.dt.date\n# # fd1.LAST_PROMOTION_DATE.dtypespd\n# pd.to_datetime(da)\n# # da.date()\n# np.datetime64(da)\nda.date().month"],"metadata":{},"outputs":[],"execution_count":139},{"cell_type":"code","source":["fd1.LAST_PROMOTION_DATE.dt.date"],"metadata":{},"outputs":[],"execution_count":140},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":141}],"metadata":{"name":"Inactive_dataset","notebookId":4336059780260427},"nbformat":4,"nbformat_minor":0}
